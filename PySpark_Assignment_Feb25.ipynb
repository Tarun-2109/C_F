{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tarun-2109/C_F/blob/main/PySpark_Assignment_Feb25.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CW1 - Amazon Bestsellers Analysis with PySpark\n",
        "\n",
        "\n",
        "In this assignment you will be tasked with exploring a dataset containing the Top 50 best-selling books from Amazon between 2009-2019. You should complete the exercises presented in the Google Colab Notebook below. This assignment will be graded using CodeGrade.\n",
        "\n",
        "Exercise 1 (5 Marks): Find the authors with the most entries in the bestseller’s lists, find the number of unique titles for each, the average rating, total number of reviews, and highest position in the ranking.\n",
        "\n",
        "Exercise 2 (5 Marks): For fiction and non-fiction books, find the average and total number of reviews for the top 10, 25, and 50 of the bestsellers lists, in each year.\n",
        "\n",
        "Exercise 3 (10 Marks): For each year, find the average price of a fiction and non-fiction book in the top 10, 25 and 50 of the bestsellers lists.\n",
        "\n",
        "Exercise 4 (10 Marks): For free books—where the price is zero—fine the number of unique titles and authors. Compare the average rating and number of reviews in each year between free and priced books.\n"
      ],
      "metadata": {
        "id": "04k66G6XOD3o"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "I6b460JnN-7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "615baa6a-1a0b-41dc-89f0-cf6766120698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# CodeGrade Tag Init1\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apache Spark uses Java, so first we must install that\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "\n",
        "# Unpack Spark from google drive\n",
        "!tar xzf /content/drive/MyDrive/spark-3.3.0-bin-hadoop3.tgz\n",
        "\n",
        "# Set up environment variables\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"spark-3.3.0-bin-hadoop3\"\n",
        "\n",
        "# Install findspark, which helps python locate the psyspark module files\n",
        "!pip install -q findspark\n",
        "import findspark\n",
        "findspark.init()\n",
        "os.listdir('/content/drive/MyDrive/')"
      ],
      "metadata": {
        "id": "Ya7WJUs2PwZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eba65dda-e87f-4478-a7d2-14614d58722a"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AdmitCard_190310035793 (1).pdf',\n",
              " 'Untitled document.gdoc',\n",
              " '20200413_235129.pdf',\n",
              " 'AP chapter 2.pdf',\n",
              " 'AP 1st chapter.pdf',\n",
              " 'preview.jpg',\n",
              " 'student_certificate.pdf',\n",
              " 'R18 B.TECH EEE II Year Syllabus (1).pdf',\n",
              " 'R18 B.TECH EEE II Year Syllabus.pdf',\n",
              " 'IMG_0089.jpg',\n",
              " 'IMG_0087 (1).jpg',\n",
              " 'IMG_0083 (1).jpg',\n",
              " 'IMG_0087.jpg',\n",
              " 'IMG_0083.jpg',\n",
              " 'TCS Hiring.pdf',\n",
              " 'Freshers',\n",
              " 'IMG_8114.JPG',\n",
              " 'IMG_8126.JPG',\n",
              " 'IMG_8118.JPG',\n",
              " 'IMG_8129.JPG',\n",
              " 'IMG_8117.JPG',\n",
              " 'IMG_8116.JPG',\n",
              " 'IMG_8113.JPG',\n",
              " 'IMG_8127.JPG',\n",
              " 'IMG_8124.JPG',\n",
              " 'IMG_8120.JPG',\n",
              " 'IMG_8128.JPG',\n",
              " 'IMG_8119.JPG',\n",
              " 'IMG_8115.JPG',\n",
              " 'IMG_8130.JPG',\n",
              " 'IMG_8121.JPG',\n",
              " 'Untitled form.gform',\n",
              " 'FRESHERS CAM-2',\n",
              " 'chintu',\n",
              " 'TARUN KUMAR (1).pdf',\n",
              " 'TARUN KUMAR.pdf',\n",
              " 'Allahabad to Trivandrum',\n",
              " 'HR Salla Tarun Tarun.gsheet',\n",
              " 'Tarun Resume - 2.pdf',\n",
              " 'TARUN KUMAR RESUME 2 (1).pdf',\n",
              " 'TARUN KUMAR RESUME 2.pdf',\n",
              " 'TARUN KUMAR RESUME-2.pdf',\n",
              " 'Team roster.gsheet',\n",
              " 'Pros and cons.gsheet',\n",
              " 'Schools in Dubai',\n",
              " '19261A0246_SALLA TARUN KUMAR.pdf',\n",
              " '20220830072013_00007.jpg',\n",
              " '20220830072013_00005.jpg',\n",
              " 'Copy of 20220830072013_00007.jpg',\n",
              " 'Last3 months.pdf',\n",
              " 'Last1 month.pdf',\n",
              " '11-11-22.zip',\n",
              " 'TARUN 2.0.pdf',\n",
              " 'zip (2).zip',\n",
              " 'zip (1).zip',\n",
              " 'zip.zip',\n",
              " '21115-00000368.zip',\n",
              " 'Information of Trainers (1).xlsx',\n",
              " 'Information of Trainers.xlsx',\n",
              " 'Copy of Proxy.pdf',\n",
              " 'Copy of Information of Trainers (2).xlsx',\n",
              " 'Copy of Information of Trainers (1).xlsx',\n",
              " 'Copy of Information of Trainers.xlsx',\n",
              " 'Copy of Proxy.gsheet',\n",
              " 'Bapatla',\n",
              " 'Adobe Scan 01 Apr 2023 (2).pdf',\n",
              " 'Adobe Scan 01 Apr 2023 (2).gdoc',\n",
              " 'Interview Sheet.gsheet',\n",
              " '[FREE - HDconvert.com] 2.mp4',\n",
              " '[FREE - HDconvert.com] 3.mp4',\n",
              " '[FREE - HDconvert.com] 1.mp4',\n",
              " '[FREE - HDconvert.com] 4.mp4',\n",
              " '[FREE - HDconvert.com] 5.mp4',\n",
              " '[FREE - HDconvert.com] 6.mp4',\n",
              " '[FREE - HDconvert.com] 7.mp4',\n",
              " '[FREE - HDconvert.com] 8.mp4',\n",
              " '[FREE - HDconvert.com] 9.mp4',\n",
              " '[FREE - HDconvert.com] 10.mp4',\n",
              " 'Companies List.gsheet',\n",
              " 'Tarun Docs',\n",
              " 'admission_letter',\n",
              " 'HUH655991835.PDF',\n",
              " 'workout and diet plan.gsheet',\n",
              " 'Google AI Studio',\n",
              " 'Colab Notebooks',\n",
              " 'RELEASE',\n",
              " 'README.md',\n",
              " 'NOTICE',\n",
              " 'LICENSE',\n",
              " 'AmazonBooks-1.csv',\n",
              " 'spark-3.3.0-bin-hadoop3.tgz',\n",
              " 'spark-3.3.0-bin-hadoop3']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, we initialse a \"SparkSession\", which handles the computations\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder\\\n",
        "        .master(\"local\")\\\n",
        "        .appName(\"Colab\")\\\n",
        "        .config('spark.ui.port', '4050')\\\n",
        "        .getOrCreate()\n",
        "\n",
        "from pyspark.sql import functions as F"
      ],
      "metadata": {
        "id": "qoS2qInhP_jy"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the AmazonBooks.csv file into your notebook as a pyspark dataframe\n",
        "\n",
        "CsvPath = '/content/drive/MyDrive/AmazonBooks-1.csv'\n",
        "\n",
        "# Load .csv with header, ',' seperators and inferred schema\n",
        "BooksDF = spark.read\\\n",
        "                     .option('header', 'True')\\\n",
        "                     .option('sep', ',')\\\n",
        "                     .option('inferSchema', 'True')\\\n",
        "                     .csv(CsvPath)"
      ],
      "metadata": {
        "id": "u_sX_aYiGMrH"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade Tag Init3\n",
        "\n",
        "BooksDF.printSchema()\n",
        "BooksDF.show()"
      ],
      "metadata": {
        "id": "kS0QdyQjG8yK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecf1dd47-5911-43c1-b469-aa83e6ba5dd4"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- Name: string (nullable = true)\n",
            " |-- Author: string (nullable = true)\n",
            " |-- User Rating: double (nullable = true)\n",
            " |-- Reviews: integer (nullable = true)\n",
            " |-- Price: integer (nullable = true)\n",
            " |-- Year: integer (nullable = true)\n",
            " |-- Genre: string (nullable = true)\n",
            " |-- Rank: integer (nullable = true)\n",
            "\n",
            "+--------------------+----------------+-----------+-------+-----+----+-----------+----+\n",
            "|                Name|          Author|User Rating|Reviews|Price|Year|      Genre|Rank|\n",
            "+--------------------+----------------+-----------+-------+-----+----+-----------+----+\n",
            "|            The Help|Kathryn Stockett|        4.8|  13871|    6|2009|    Fiction|   1|\n",
            "|Where the Wild Th...|  Maurice Sendak|        4.8|   9967|   13|2009|    Fiction|   2|\n",
            "|The Last Olympian...|    Rick Riordan|        4.8|   4628|    7|2009|    Fiction|   3|\n",
            "|Diary of a Wimpy ...|     Jeff Kinney|        4.8|   3837|   15|2009|    Fiction|   4|\n",
            "|            Watchmen|      Alan Moore|        4.8|   3829|   42|2009|    Fiction|   5|\n",
            "|Liberty and Tyran...|   Mark R. Levin|        4.8|   3828|   15|2009|Non Fiction|   6|\n",
            "|Dog Days (Diary o...|     Jeff Kinney|        4.8|   3181|   12|2009|    Fiction|   7|\n",
            "|Mastering the Art...|     Julia Child|        4.8|   2926|   27|2009|Non Fiction|   8|\n",
            "|Have a Little Fai...|     Mitch Albom|        4.8|   1930|    4|2009|Non Fiction|   9|\n",
            "|  The 5000 Year Leap|W. Cleon Skousen|        4.8|   1680|   12|2009|Non Fiction|  10|\n",
            "|       The Love Dare|Stephen Kendrick|        4.8|   1655|   13|2009|Non Fiction|  11|\n",
            "|Twilight (The Twi...| Stephenie Meyer|        4.7|  11676|    9|2009|    Fiction|  12|\n",
            "|The Guernsey Lite...|Mary Ann Shaffer|        4.7|   8587|   10|2009|    Fiction|  13|\n",
            "|The Girl Who Play...|   Stieg Larsson|        4.7|   7251|   16|2009|    Fiction|  14|\n",
            "|Eclipse (Twilight...| Stephenie Meyer|        4.7|   5505|    7|2009|    Fiction|  15|\n",
            "|  Eclipse (Twilight)| Stephenie Meyer|        4.7|   5505|   18|2009|    Fiction|  16|\n",
            "|    The Last Lecture|    Randy Pausch|        4.7|   4028|    9|2009|Non Fiction|  17|\n",
            "|The Twilight Saga...| Stephenie Meyer|        4.7|   3801|   82|2009|    Fiction|  18|\n",
            "|Crazy Love: Overw...|    Francis Chan|        4.7|   1542|   14|2009|Non Fiction|  19|\n",
            "|   Sookie Stackhouse|Charlaine Harris|        4.7|    973|   25|2009|    Fiction|  20|\n",
            "+--------------------+----------------+-----------+-------+-----+----+-----------+----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pyspark.sql.functions countains all the transformations and actions you will\n",
        "# need\n",
        "from pyspark.sql import functions as F"
      ],
      "metadata": {
        "id": "TuAo0k6bG0Zq"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 1\n",
        "\n",
        "Find the authors with the most entries in the bestsellers lists. Find the number of unique titles for each author, the average rating, total number of reviews and highest position in the ranking. Create a dataframe where the columns are:\n",
        "\n",
        "Author, Number of titles, Average Rating, Total Ratings, Highest Position\n",
        "\n",
        "Sort by the number of titles in descending order."
      ],
      "metadata": {
        "id": "nuSgzl6DZ33Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade Tag Ex1\n",
        "### Create a dataframe that contains, for each author, the number of unique\n",
        "### books, the average rating, the number of reviews and the highest rank reached\n",
        "\n",
        "Bestselling_Authors = BooksDF.groupBy(\"Author\").agg(F.countDistinct(\"Name\").alias(\"Number_of_Titles\"),\n",
        "                              F.avg(\"User Rating\").alias(\"Average_Rating\"),\n",
        "                              F.sum(\"Reviews\").alias(\"Total_Ratings\"),\n",
        "                              F.min(\"Rank\").alias(\"Highest_Position\")).orderBy(F.desc(\"Number_of_Titles\"))\n",
        "\n",
        "Bestselling_Authors = Bestselling_Authors.select(F.col(\"Author\"),\n",
        "                                     F.col(\"Number_of_Titles\"),\n",
        "                                     F.col(\"Average_Rating\"),\n",
        "                                     F.col(\"Total_Ratings\"),\n",
        "                                     F.col(\"Highest_Position\"))\n",
        "\n",
        "Bestselling_Authors.show()"
      ],
      "metadata": {
        "id": "AzsBLIkNgdHm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "666d64e3-d093-4a2e-93fe-8d8f3468b050"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------+------------------+-------------+----------------+\n",
            "|          Author|Number_of_Titles|    Average_Rating|Total_Ratings|Highest_Position|\n",
            "+----------------+----------------+------------------+-------------+----------------+\n",
            "|     Jeff Kinney|              13| 4.807692307692306|        93529|               4|\n",
            "|    Rick Riordan|              10|4.7727272727272725|        44169|               3|\n",
            "| Stephenie Meyer|               8|             4.675|       108273|              12|\n",
            "|      Dav Pilkey|               7|               4.9|        82541|               4|\n",
            "|   Bill O'Reilly|               6| 4.642857142857143|        63787|              13|\n",
            "|    J.K. Rowling|               6|              4.45|        70535|               2|\n",
            "| Suzanne Collins|               6| 4.666666666666667|       315502|               3|\n",
            "|       E L James|               5| 4.233333333333333|       178011|              31|\n",
            "|    John Grisham|               5|               4.4|        60961|              31|\n",
            "|   Stieg Larsson|               4|4.6000000000000005|        51114|              12|\n",
            "|    Stephen King|               4|             4.525|        29385|              18|\n",
            "|      Ina Garten|               4|               4.7|        15066|               9|\n",
            "|Charlaine Harris|               4|              4.45|         6532|              20|\n",
            "|    Gary Chapman|               3| 4.741666666666666|       190132|               7|\n",
            "|   Joanna Gaines|               3| 4.833333333333333|        30158|               9|\n",
            "|   Veronica Roth|               3|4.3999999999999995|        78190|              22|\n",
            "|    Ree Drummond|               3|               4.8|         8967|               7|\n",
            "|Malcolm Gladwell|               3|               4.5|        28997|              20|\n",
            "|      Glenn Beck|               3| 4.566666666666666|         2634|              31|\n",
            "|       Dan Brown|               3|               4.2|        57302|              44|\n",
            "+----------------+----------------+------------------+-------------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 2\n",
        "\n",
        "For fiction and non-fiction books, find the average rating, the average number of reviews, the total number of reviews and the average price in the bestsellers list, for each year. Create a dataframe where the columns are:\n",
        "\n",
        "Year, Genre, Average Rating, Average Number of Reviews, Total Reviews, Average Price,\n",
        "\n",
        "Sort by the year in ascending order."
      ],
      "metadata": {
        "id": "l_DwW41dX9aT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade Tag Ex2\n",
        "### Create a dataframe that shows the average user rating, average number of\n",
        "### reviews, total number of reviews and average price in each year of the\n",
        "### bestsellers list\n",
        "\n",
        "Bestselling_Each_year = BooksDF.groupby(\"Year\", \"Genre\").agg(F.avg(\"User Rating\").alias(\"Average_Rating\"),\n",
        "                                                             F.avg(\"Reviews\").alias(\"Average_Number_of_Reviews\"),\n",
        "                                                             F.sum(\"Reviews\").alias(\"Total_Reviews\"),\n",
        "                                                             F.avg(\"Price\").alias(\"Average_Price\")).orderBy(F.asc(\"Year\"))\n",
        "\n",
        "Bestselling_Each_year = Bestselling_Each_year.select(F.col(\"Year\"),\n",
        "                                     F.col(\"Genre\"),\n",
        "                                     F.col(\"Average_Rating\"),\n",
        "                                     F.col(\"Average_Number_of_Reviews\"),\n",
        "                                     F.col(\"Total_Reviews\"),\n",
        "                                     F.col(\"Average_Price\"))\n",
        "\n",
        "Bestselling_Each_year.show()"
      ],
      "metadata": {
        "id": "Uu7Y9M_7fFM6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af94f368-2970-41af-8a17-2e7b526a68d5"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+------------------+-------------------------+-------------+------------------+\n",
            "|Year|      Genre|    Average_Rating|Average_Number_of_Reviews|Total_Reviews|     Average_Price|\n",
            "+----+-----------+------------------+-------------------------+-------------+------------------+\n",
            "|2009|    Fiction| 4.591666666666667|        6534.333333333333|       156824|15.583333333333334|\n",
            "|2009|Non Fiction| 4.576923076923077|        3026.230769230769|        78682| 15.23076923076923|\n",
            "|2010|    Fiction|             4.615|                  8409.25|       168185|               9.7|\n",
            "|2010|Non Fiction|4.5200000000000005|       3526.5333333333333|       105796|              16.0|\n",
            "|2011|    Fiction|4.6190476190476195|       10335.285714285714|       217041|11.619047619047619|\n",
            "|2011|Non Fiction| 4.513793103448277|        6482.758620689655|       188000|17.620689655172413|\n",
            "|2012|    Fiction| 4.495238095238096|       19896.238095238095|       417821|12.285714285714286|\n",
            "|2012|Non Fiction| 4.558620689655172|        8162.931034482759|       236725|17.482758620689655|\n",
            "|2013|    Fiction| 4.545833333333333|       19986.833333333332|       479684|10.708333333333334|\n",
            "|2013|Non Fiction| 4.561538461538462|        6739.346153846154|       175223|18.192307692307693|\n",
            "|2014|    Fiction|  4.63103448275862|       19382.862068965518|       562103|10.172413793103448|\n",
            "|2014|Non Fiction|  4.60952380952381|       10994.952380952382|       230894| 20.80952380952381|\n",
            "|2015|    Fiction| 4.652941176470588|       23706.117647058825|       403004| 9.352941176470589|\n",
            "|2015|Non Fiction| 4.645454545454545|        9353.484848484848|       308665|10.969696969696969|\n",
            "|2016|Non Fiction|  4.65483870967742|       10906.387096774193|       338098|13.516129032258064|\n",
            "|2016|    Fiction| 4.715789473684208|       19563.263157894737|       371702|12.631578947368421|\n",
            "|2017|    Fiction| 4.737499999999998|       14611.833333333334|       350684| 8.833333333333334|\n",
            "|2017|Non Fiction| 4.588461538461538|       11297.538461538461|       293736| 13.73076923076923|\n",
            "|2018|Non Fiction| 4.617241379310345|       14813.862068965518|       429602|11.793103448275861|\n",
            "|2018|    Fiction| 4.738095238095236|        12710.42857142857|       266919| 8.761904761904763|\n",
            "+----+-----------+------------------+-------------------------+-------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 3\n",
        "\n",
        "For each year, find the average price of fiction and non-fiction books in the top 10, 25 and 50 of the bestsellers list. Make a dataframe where the columns are:\n",
        "\n",
        "Year, Genre, Avg Price in Top 10, Avg Price in Top 25 and Avg Price in Top 50\n",
        "\n",
        "Sort by the year in ascending order."
      ],
      "metadata": {
        "id": "WIEZ21wyUn8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Final\n",
        "# CodeGrade Tag Ex3\n",
        "### Create a DataFrame that shows the average price for books in the top 10, 25\n",
        "### and 50 of the bestsellers list, for each year in the dataset\n",
        "\n",
        "BooksDF_sorted = BooksDF.orderBy(F.col(\"Reviews\").desc())\n",
        "\n",
        "\n",
        "Top10_DF = BooksDF_sorted.filter(F.col(\"Rank\") <= 10)\n",
        "Top25_DF = BooksDF_sorted.filter(F.col(\"Rank\") <= 25)\n",
        "Top50_DF = BooksDF_sorted.filter(F.col(\"Rank\") <= 50)\n",
        "\n",
        "Top10_Avg_price_DF = Top10_DF.groupby(\"Year\", \"Genre\").agg(F.avg(\"Price\").alias(\"Avg_Price_Top10\"))\n",
        "Top25_Avg_price_DF = Top25_DF.groupby(\"Year\", \"Genre\").agg(F.avg(\"Price\").alias(\"Avg_Price_Top25\"))\n",
        "Top50_Avg_price_DF = Top50_DF.groupby(\"Year\", \"Genre\").agg(F.avg(\"Price\").alias(\"Avg_Price_Top50\"))\n",
        "\n",
        "Final_DF = Top10_Avg_price_DF.join(Top25_Avg_price_DF, [\"Year\", \"Genre\"], \"inner\").join(Top50_Avg_price_DF, [\"Year\", \"Genre\"], \"inner\")\n",
        "\n",
        "Final_DF = Final_DF.orderBy(F.asc(\"Year\"))\n",
        "\n",
        "Final_DF.show()"
      ],
      "metadata": {
        "id": "LHaC8-59G3Hr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec2c878-4af1-4229-be8e-08afd1988702"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+-----------+------------------+------------------+------------------+\n",
            "|Year|      Genre|   Avg_Price_Top10|   Avg_Price_Top25|   Avg_Price_Top50|\n",
            "+----+-----------+------------------+------------------+------------------+\n",
            "|2009|    Fiction|15.833333333333334|18.866666666666667|15.583333333333334|\n",
            "|2009|Non Fiction|              14.5|              19.1| 15.23076923076923|\n",
            "|2010|    Fiction|10.777777777777779|10.928571428571429|               9.7|\n",
            "|2010|Non Fiction|              16.0|15.636363636363637|              16.0|\n",
            "|2011|    Fiction|            10.375|10.923076923076923|11.619047619047619|\n",
            "|2011|Non Fiction|              12.0|15.666666666666666|17.620689655172413|\n",
            "|2012|    Fiction|13.333333333333334|              11.9|12.285714285714286|\n",
            "|2012|Non Fiction|             17.25|17.933333333333334|17.482758620689655|\n",
            "|2013|    Fiction| 9.333333333333334| 9.357142857142858|10.708333333333334|\n",
            "|2013|Non Fiction|               8.0|14.363636363636363|18.192307692307693|\n",
            "|2014|    Fiction| 5.666666666666667|            11.125|10.172413793103448|\n",
            "|2014|Non Fiction|             12.25|13.777777777777779| 20.80952380952381|\n",
            "|2015|    Fiction| 6.333333333333333| 6.666666666666667| 9.352941176470589|\n",
            "|2015|Non Fiction|             11.25| 9.692307692307692|10.969696969696969|\n",
            "|2016|Non Fiction|22.333333333333332|             11.75|13.516129032258064|\n",
            "|2016|    Fiction|12.285714285714286|13.923076923076923|12.631578947368421|\n",
            "|2017|    Fiction|             12.75|  8.61111111111111| 8.833333333333334|\n",
            "|2017|Non Fiction|              15.0| 9.571428571428571| 13.73076923076923|\n",
            "|2018|Non Fiction|               9.5|              13.3|11.793103448275861|\n",
            "|2018|    Fiction|               7.0| 8.066666666666666| 8.761904761904763|\n",
            "+----+-----------+------------------+------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 4\n",
        "\n",
        "For free books, find the total number of unique title and author, store these as variables called ```free_titles``` and ```free_authors```.\n",
        "\n",
        "Compare the average rating and number of reviews for free and priced books, in each year of the dataset. Create a dataframe where the columns are:\n",
        "\n",
        "Year, Avg Rating Free, Avg Rating Priced, Total Ratings Free, Total Ratings Priced\n",
        "\n",
        "Sort by the year in ascending order."
      ],
      "metadata": {
        "id": "ciUez_m4aYmO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade Tag Ex4a\n",
        "### Find the number of free books in the dataset and the number of authors\n",
        "### who wrote them\n",
        "\n",
        "Free_Books_df = BooksDF.filter(F.col(\"Price\") == 0)\n",
        "Priced_Books_df = BooksDF.filter(F.col(\"Price\") > 0)\n",
        "\n",
        "Free_titles = Free_Books_df.select(\"Name\").distinct().count()\n",
        "Free_authors = Free_Books_df.select(\"Author\").distinct().count()\n",
        "\n",
        "print(f\"Number of unique titles in free books: {Free_titles}\")\n",
        "print(f\"Number of unique authors in free books: {Free_authors}\")"
      ],
      "metadata": {
        "id": "VXReWf6GmhIw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b775dab-2e33-4055-f5e2-f31438a8b9f5"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique titles in free books: 9\n",
            "Number of unique authors in free books: 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CodeGrade Tag Exb\n",
        "### Create a dataframe that has, for each year, the average rating and number of\n",
        "### user reviews for free books and priced books\n",
        "\n",
        "Avg_Free_Books = Free_Books_df.groupby(\"Year\").agg(F.avg(\"User Rating\").alias(\"Avg_Rating_Free\"),\n",
        "                                                   F.sum(\"Reviews\").alias(\"Total_Ratings_Free\"))\n",
        "Avg_Priced_Books = Priced_Books_df.groupby(\"Year\").agg(F.avg(\"User Rating\").alias(\"Avg_Rating_Priced\"),\n",
        "                                                       F.sum(\"Reviews\").alias(\"Total_Ratings_Priced\"))\n",
        "Average_Final_DF = Avg_Free_Books.join(Avg_Priced_Books, [\"Year\"], \"inner\")\n",
        "Average_Final_DF = Average_Final_DF.orderBy(F.asc(\"Year\"))\n",
        "Average_Final_DF.show()"
      ],
      "metadata": {
        "id": "shnUw1VXhbCJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee422d80-7e6a-4eae-f6f4-f4dd4d2f8524"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+---------------+------------------+-----------------+--------------------+\n",
            "|Year|Avg_Rating_Free|Total_Ratings_Free|Avg_Rating_Priced|Total_Ratings_Priced|\n",
            "+----+---------------+------------------+-----------------+--------------------+\n",
            "|2010|            4.6|              2122|4.557142857142857|              271859|\n",
            "|2011|            4.8|              4505|4.553061224489797|              400536|\n",
            "|2013|            4.8|             33046|          4.54375|              621861|\n",
            "|2014|           4.75|             32738|4.610869565217391|              760259|\n",
            "|2015|            4.8|             26234|4.644897959183671|              685435|\n",
            "|2016|            4.8|             29008|4.672916666666665|              680792|\n",
            "|2017|            4.8|              5836|4.657142857142857|              638584|\n",
            "+----+---------------+------------------+-----------------+--------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F0Ul25BG3Xqt"
      },
      "execution_count": 79,
      "outputs": []
    }
  ]
}